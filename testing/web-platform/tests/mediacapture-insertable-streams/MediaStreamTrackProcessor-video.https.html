<
!
doctype
html
>
<
html
>
<
head
>
<
title
>
MediaStreamTrackProcessor
<
/
title
>
<
link
rel
=
"
help
"
href
=
"
https
:
/
/
w3c
.
github
.
io
/
mediacapture
-
insertable
-
streams
"
>
<
/
head
>
<
body
>
<
p
class
=
"
instructions
"
>
When
prompted
use
the
accept
button
to
give
permission
to
use
your
audio
and
video
devices
.
<
/
p
>
<
h1
class
=
"
instructions
"
>
Description
<
/
h1
>
<
p
class
=
"
instructions
"
>
This
test
checks
that
processing
captured
video
MediaStreamTracks
works
as
expected
.
<
/
p
>
<
script
src
=
/
resources
/
testharness
.
js
>
<
/
script
>
<
script
src
=
/
resources
/
testharnessreport
.
js
>
<
/
script
>
<
canvas
id
=
"
canvas
"
>
<
/
canvas
>
<
script
>
const
pixelColour
=
[
50
100
150
255
]
;
function
makeVideoFrame
(
timestamp
)
{
const
height
=
240
;
const
width
=
320
;
const
canvas
=
new
OffscreenCanvas
(
width
height
)
;
const
ctx
=
canvas
.
getContext
(
'
2d
'
)
;
ctx
.
fillStyle
=
rgba
(
{
pixelColour
[
0
]
}
{
pixelColour
[
1
]
}
{
pixelColour
[
2
]
}
{
pixelColour
[
3
]
}
)
;
ctx
.
fillRect
(
0
0
width
height
)
;
return
new
VideoFrame
(
canvas
.
transferToImageBitmap
(
)
{
timestamp
}
)
;
}
/
/
Assert
that
a
pixel
in
RGBA
bytes
approximately
matches
the
expected
value
.
function
assertPixel
(
t
bytes
expected
)
{
t
.
step
(
(
)
=
>
{
assert_equals
(
bytes
.
length
expected
.
length
"
pixel
bytes
not
correct
length
"
)
for
(
let
i
=
0
;
i
<
bytes
.
length
;
i
+
+
)
{
assert_less_than
(
bytes
[
i
]
expected
[
i
]
+
2
"
Mismatched
pixel
"
)
;
assert_greater_than
(
bytes
[
i
]
expected
[
i
]
-
2
"
Mismatched
pixel
"
)
;
}
}
)
;
}
promise_test
(
async
t
=
>
{
const
height
=
240
;
const
width
=
320
;
const
canvas
=
document
.
getElementById
(
'
canvas
'
)
;
canvas
.
width
=
width
;
canvas
.
height
=
height
;
const
ctx
=
canvas
.
getContext
(
'
2d
'
)
;
ctx
.
fillStyle
=
rgba
(
{
pixelColour
[
0
]
}
{
pixelColour
[
1
]
}
{
pixelColour
[
2
]
}
{
pixelColour
[
3
]
}
)
;
ctx
.
fillRect
(
0
0
width
height
)
;
const
stream
=
canvas
.
captureStream
(
10
)
;
assert_equals
(
stream
.
getVideoTracks
(
)
.
length
1
)
;
const
videoTrack
=
stream
.
getVideoTracks
(
)
[
0
]
;
return
new
Promise
(
async
(
resolve
reject
)
=
>
{
const
writableStream
=
new
WritableStream
(
{
write
(
videoFrame
)
{
t
.
step
(
(
)
=
>
{
assert_true
(
videoFrame
instanceof
VideoFrame
)
;
assert_equals
(
videoFrame
.
codedWidth
320
)
;
assert_not_equals
(
videoFrame
.
timestamp
null
)
;
}
)
;
videoFrame
.
createImageBitmap
(
)
.
then
(
bitmap
=
>
{
const
canvas
=
new
OffscreenCanvas
(
bitmap
.
width
bitmap
.
height
)
;
const
canvasCtx
=
canvas
.
getContext
(
'
2d
'
)
;
canvasCtx
.
drawImage
(
bitmap
0
0
)
;
/
/
Check
the
provided
frame
matches
the
canvas
input
.
const
imgData
=
canvasCtx
.
getImageData
(
0
0
canvas
.
width
canvas
.
height
)
;
for
(
let
i
=
0
;
i
<
canvas
.
height
;
i
+
+
)
{
for
(
let
j
=
0
;
j
<
canvas
.
width
;
j
+
+
)
{
assertPixel
(
t
imgData
.
data
.
slice
(
i
*
canvas
.
width
+
j
*
4
i
*
canvas
.
width
+
j
*
4
+
4
)
pixelColour
)
;
}
}
resolve
(
)
;
}
)
;
}
close
(
)
{
fail
(
"
Closed
"
)
;
}
abort
(
err
)
{
fail
(
"
Sink
error
:
"
err
)
;
}
}
)
;
const
videoTrackProcessor
=
new
MediaStreamTrackProcessor
(
videoTrack
)
;
videoTrackProcessor
.
readable
.
pipeTo
(
writableStream
)
;
t
.
step
(
(
)
=
>
{
assert_false
(
videoTrack
.
muted
"
Video
track
shouldn
'
t
be
muted
after
attaching
Processing
.
"
)
;
}
)
;
}
)
;
}
"
Tests
that
creating
a
Video
MediaStreamTrackProcessor
works
as
expected
"
)
;
promise_test
(
async
t
=
>
{
const
iAmNotATrack
=
"
notatrack
"
;
assert_throws_js
(
TypeError
(
)
=
>
{
new
MediaStreamTrackProcessor
(
iAmNotATrack
)
}
)
;
}
"
Tests
that
construction
of
a
MediaStreamTrackProcessor
with
an
invalid
track
throws
.
"
)
;
promise_test
(
async
t
=
>
{
const
bufferSize
=
3
;
const
framesToSend
=
10
;
const
generatedTrack
=
new
MediaStreamTrackGenerator
(
"
video
"
)
;
const
frameWriter
=
generatedTrack
.
writable
.
getWriter
(
)
;
const
trackProcessor
=
new
MediaStreamTrackProcessor
(
generatedTrack
bufferSize
)
;
const
reader
=
trackProcessor
.
readable
.
getReader
(
)
;
/
/
Enqueue
many
frames
one
after
the
other
.
await
frameWriter
.
ready
;
for
(
let
i
=
0
;
i
<
framesToSend
;
i
+
+
)
{
await
frameWriter
.
write
(
makeVideoFrame
(
i
)
)
}
/
/
Our
reader
should
only
be
provided
with
the
|
bufferSize
|
latest
frames
.
const
framesSeen
=
0
;
for
(
let
i
=
0
;
i
<
bufferSize
;
i
+
+
)
{
const
videoFrame
=
(
await
reader
.
read
(
)
)
.
value
;
t
.
step
(
(
)
=
>
{
assert_true
(
videoFrame
instanceof
VideoFrame
"
Invalid
type
of
videoFrame
"
)
;
assert_greater_than_equal
(
videoFrame
.
timestamp
framesToSend
-
bufferSize
"
Received
buffered
frame
which
should
have
been
dropped
"
)
;
}
)
;
}
return
Promise
.
resolve
(
)
;
}
"
Tests
that
only
the
maxBufferSize
most
recent
frames
are
stored
"
)
;
<
/
script
>
<
/
body
>
<
/
html
>
