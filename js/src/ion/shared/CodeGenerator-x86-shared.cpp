/
*
-
*
-
Mode
:
C
+
+
;
tab
-
width
:
8
;
indent
-
tabs
-
mode
:
nil
;
c
-
basic
-
offset
:
4
-
*
-
*
vim
:
set
ts
=
4
sw
=
4
et
tw
=
79
:
*
*
*
*
*
*
*
BEGIN
LICENSE
BLOCK
*
*
*
*
*
*
Version
:
MPL
1
.
1
/
GPL
2
.
0
/
LGPL
2
.
1
*
*
The
contents
of
this
file
are
subject
to
the
Mozilla
Public
License
Version
*
1
.
1
(
the
"
License
"
)
;
you
may
not
use
this
file
except
in
compliance
with
*
the
License
.
You
may
obtain
a
copy
of
the
License
at
*
http
:
/
/
www
.
mozilla
.
org
/
MPL
/
*
*
Software
distributed
under
the
License
is
distributed
on
an
"
AS
IS
"
basis
*
WITHOUT
WARRANTY
OF
ANY
KIND
either
express
or
implied
.
See
the
License
*
for
the
specific
language
governing
rights
and
limitations
under
the
*
License
.
*
*
The
Original
Code
is
Mozilla
Communicator
client
code
released
*
March
31
1998
.
*
*
The
Initial
Developer
of
the
Original
Code
is
*
Netscape
Communications
Corporation
.
*
Portions
created
by
the
Initial
Developer
are
Copyright
(
C
)
1998
*
the
Initial
Developer
.
All
Rights
Reserved
.
*
*
Contributor
(
s
)
:
*
David
Anderson
<
danderson
mozilla
.
com
>
*
*
Alternatively
the
contents
of
this
file
may
be
used
under
the
terms
of
*
either
of
the
GNU
General
Public
License
Version
2
or
later
(
the
"
GPL
"
)
*
or
the
GNU
Lesser
General
Public
License
Version
2
.
1
or
later
(
the
"
LGPL
"
)
*
in
which
case
the
provisions
of
the
GPL
or
the
LGPL
are
applicable
instead
*
of
those
above
.
If
you
wish
to
allow
use
of
your
version
of
this
file
only
*
under
the
terms
of
either
the
GPL
or
the
LGPL
and
not
to
allow
others
to
*
use
your
version
of
this
file
under
the
terms
of
the
MPL
indicate
your
*
decision
by
deleting
the
provisions
above
and
replace
them
with
the
notice
*
and
other
provisions
required
by
the
GPL
or
the
LGPL
.
If
you
do
not
delete
*
the
provisions
above
a
recipient
may
use
your
version
of
this
file
under
*
the
terms
of
any
one
of
the
MPL
the
GPL
or
the
LGPL
.
*
*
*
*
*
*
*
END
LICENSE
BLOCK
*
*
*
*
*
*
/
#
include
"
jscntxt
.
h
"
#
include
"
jscompartment
.
h
"
#
include
"
CodeGenerator
-
x86
-
shared
.
h
"
#
include
"
CodeGenerator
-
shared
-
inl
.
h
"
#
include
"
ion
/
IonFrames
.
h
"
#
include
"
ion
/
MoveEmitter
.
h
"
#
include
"
ion
/
IonCompartment
.
h
"
using
namespace
js
;
using
namespace
js
:
:
ion
;
CodeGeneratorX86Shared
:
:
CodeGeneratorX86Shared
(
MIRGenerator
*
gen
LIRGraph
&
graph
)
:
CodeGeneratorShared
(
gen
graph
)
deoptLabel_
(
NULL
)
{
}
bool
CodeGeneratorX86Shared
:
:
generatePrologue
(
)
{
/
/
Note
that
this
automatically
sets
MacroAssembler
:
:
framePushed
(
)
.
masm
.
reserveStack
(
frameSize
(
)
)
;
/
/
Allocate
returnLabel_
on
the
heap
so
we
don
'
t
run
it
'
s
destructor
and
/
/
assert
-
not
-
bound
in
debug
mode
on
compilation
failure
.
returnLabel_
=
new
HeapLabel
(
)
;
return
true
;
}
bool
CodeGeneratorX86Shared
:
:
generateEpilogue
(
)
{
masm
.
bind
(
returnLabel_
)
;
/
/
Pop
the
stack
we
allocated
at
the
start
of
the
function
.
masm
.
freeStack
(
frameSize
(
)
)
;
JS_ASSERT
(
masm
.
framePushed
(
)
=
=
0
)
;
masm
.
ret
(
)
;
return
true
;
}
bool
OutOfLineBailout
:
:
accept
(
CodeGeneratorX86Shared
*
codegen
)
{
return
codegen
-
>
visitOutOfLineBailout
(
this
)
;
}
bool
CodeGeneratorX86Shared
:
:
visitGoto
(
LGoto
*
jump
)
{
LBlock
*
target
=
jump
-
>
target
(
)
-
>
lir
(
)
;
/
/
Don
'
t
bother
emitting
a
jump
if
we
'
ll
flow
through
to
the
next
block
.
if
(
isNextBlock
(
target
)
)
return
true
;
masm
.
jmp
(
target
-
>
label
(
)
)
;
return
true
;
}
bool
CodeGeneratorX86Shared
:
:
visitTestIAndBranch
(
LTestIAndBranch
*
test
)
{
const
LAllocation
*
opd
=
test
-
>
getOperand
(
0
)
;
LBlock
*
ifTrue
=
test
-
>
ifTrue
(
)
-
>
lir
(
)
;
LBlock
*
ifFalse
=
test
-
>
ifFalse
(
)
-
>
lir
(
)
;
/
/
Test
the
operand
masm
.
testl
(
ToRegister
(
opd
)
ToRegister
(
opd
)
)
;
if
(
isNextBlock
(
ifFalse
)
)
{
masm
.
j
(
Assembler
:
:
NonZero
ifTrue
-
>
label
(
)
)
;
}
else
if
(
isNextBlock
(
ifTrue
)
)
{
masm
.
j
(
Assembler
:
:
Zero
ifFalse
-
>
label
(
)
)
;
}
else
{
masm
.
j
(
Assembler
:
:
Zero
ifFalse
-
>
label
(
)
)
;
masm
.
jmp
(
ifTrue
-
>
label
(
)
)
;
}
return
true
;
}
bool
CodeGeneratorX86Shared
:
:
visitCompareI
(
LCompareI
*
comp
)
{
const
LAllocation
*
left
=
comp
-
>
getOperand
(
0
)
;
const
LAllocation
*
right
=
comp
-
>
getOperand
(
1
)
;
const
LDefinition
*
def
=
comp
-
>
getDef
(
0
)
;
/
/
If
the
register
we
'
re
defining
is
a
single
byte
register
/
/
take
advantage
of
the
setCC
instruction
if
(
GeneralRegisterSet
(
Registers
:
:
SingleByteRegs
)
.
has
(
ToRegister
(
def
)
)
)
{
masm
.
xorl
(
ToRegister
(
def
)
ToRegister
(
def
)
)
;
masm
.
cmpl
(
ToRegister
(
left
)
ToOperand
(
right
)
)
;
masm
.
setCC
(
comp
-
>
condition
(
)
ToRegister
(
def
)
)
;
return
true
;
}
Label
ifTrue
;
masm
.
movl
(
Imm32
(
1
)
ToRegister
(
def
)
)
;
masm
.
cmpl
(
ToRegister
(
left
)
ToOperand
(
right
)
)
;
masm
.
j
(
comp
-
>
condition
(
)
&
ifTrue
)
;
masm
.
movl
(
Imm32
(
0
)
ToRegister
(
def
)
)
;
masm
.
bind
(
&
ifTrue
)
;
return
true
;
}
bool
CodeGeneratorX86Shared
:
:
visitCompareIAndBranch
(
LCompareIAndBranch
*
comp
)
{
const
LAllocation
*
left
=
comp
-
>
getOperand
(
0
)
;
const
LAllocation
*
right
=
comp
-
>
getOperand
(
1
)
;
LBlock
*
ifTrue
=
comp
-
>
ifTrue
(
)
-
>
lir
(
)
;
LBlock
*
ifFalse
=
comp
-
>
ifFalse
(
)
-
>
lir
(
)
;
Assembler
:
:
Condition
cond
=
comp
-
>
condition
(
)
;
/
/
Compare
the
operands
masm
.
cmpl
(
ToRegister
(
left
)
ToOperand
(
right
)
)
;
/
/
Take
advantage
of
block
fallthrough
when
possible
if
(
isNextBlock
(
ifFalse
)
)
{
masm
.
j
(
cond
ifTrue
-
>
label
(
)
)
;
}
else
if
(
isNextBlock
(
ifTrue
)
)
{
masm
.
j
(
Assembler
:
:
inverseCondition
(
cond
)
ifFalse
-
>
label
(
)
)
;
}
else
{
masm
.
j
(
cond
ifTrue
-
>
label
(
)
)
;
masm
.
jmp
(
ifFalse
-
>
label
(
)
)
;
}
return
true
;
}
bool
CodeGeneratorX86Shared
:
:
generateOutOfLineCode
(
)
{
if
(
!
CodeGeneratorShared
:
:
generateOutOfLineCode
(
)
)
return
false
;
if
(
deoptLabel_
)
{
/
/
All
non
-
table
-
based
bailouts
will
go
here
.
masm
.
bind
(
deoptLabel_
)
;
/
/
Push
the
frame
size
so
the
handler
can
recover
the
IonScript
.
masm
.
push
(
Imm32
(
frameSize
(
)
)
)
;
IonCompartment
*
ion
=
gen
-
>
cx
-
>
compartment
-
>
ionCompartment
(
)
;
IonCode
*
handler
=
ion
-
>
getGenericBailoutHandler
(
gen
-
>
cx
)
;
if
(
!
handler
)
return
false
;
masm
.
jmp
(
handler
-
>
raw
(
)
Relocation
:
:
CODE
)
;
}
return
true
;
}
bool
CodeGeneratorX86Shared
:
:
bailoutIf
(
Assembler
:
:
Condition
condition
LSnapshot
*
snapshot
)
{
if
(
!
encode
(
snapshot
)
)
return
false
;
/
/
Though
the
assembler
doesn
'
t
track
all
frame
pushes
at
least
make
sure
/
/
the
known
value
makes
sense
.
We
can
'
t
use
bailout
tables
if
the
stack
/
/
isn
'
t
properly
aligned
to
the
static
frame
size
.
JS_ASSERT_IF
(
frameClass_
!
=
FrameSizeClass
:
:
None
(
)
frameClass_
.
frameSize
(
)
=
=
masm
.
framePushed
(
)
)
;
/
/
On
x64
bailout
tables
are
pointless
because
16
extra
bytes
are
/
/
reserved
per
external
jump
whereas
it
takes
only
10
bytes
to
encode
a
/
/
a
non
-
table
based
bailout
.
#
ifdef
JS_CPU_X86
if
(
assignBailoutId
(
snapshot
)
)
{
uint8
*
code
=
deoptTable_
-
>
raw
(
)
+
snapshot
-
>
bailoutId
(
)
*
BAILOUT_TABLE_ENTRY_SIZE
;
masm
.
j
(
condition
code
Relocation
:
:
EXTERNAL
)
;
return
true
;
}
#
endif
/
/
We
could
not
use
a
jump
table
either
because
all
bailout
IDs
were
/
/
reserved
or
a
jump
table
is
not
optimal
for
this
frame
size
or
/
/
platform
.
Whatever
we
will
generate
a
lazy
bailout
.
OutOfLineBailout
*
ool
=
new
OutOfLineBailout
(
snapshot
masm
.
framePushed
(
)
)
;
if
(
!
addOutOfLineCode
(
ool
)
)
return
false
;
masm
.
j
(
condition
ool
-
>
entry
(
)
)
;
return
true
;
}
bool
CodeGeneratorX86Shared
:
:
visitOutOfLineBailout
(
OutOfLineBailout
*
ool
)
{
masm
.
bind
(
ool
-
>
entry
(
)
)
;
if
(
!
deoptLabel_
)
deoptLabel_
=
new
HeapLabel
(
)
;
masm
.
push
(
Imm32
(
ool
-
>
snapshot
(
)
-
>
snapshotOffset
(
)
)
)
;
masm
.
jmp
(
deoptLabel_
)
;
return
true
;
}
bool
CodeGeneratorX86Shared
:
:
visitAddI
(
LAddI
*
ins
)
{
const
LAllocation
*
lhs
=
ins
-
>
getOperand
(
0
)
;
const
LAllocation
*
rhs
=
ins
-
>
getOperand
(
1
)
;
if
(
rhs
-
>
isConstant
(
)
)
masm
.
addl
(
Imm32
(
ToInt32
(
rhs
)
)
ToOperand
(
lhs
)
)
;
else
masm
.
addl
(
ToOperand
(
rhs
)
ToRegister
(
lhs
)
)
;
if
(
ins
-
>
snapshot
(
)
&
&
!
bailoutIf
(
Assembler
:
:
Overflow
ins
-
>
snapshot
(
)
)
)
return
false
;
return
true
;
}
bool
CodeGeneratorX86Shared
:
:
visitMulI
(
LMulI
*
ins
)
{
const
LAllocation
*
lhs
=
ins
-
>
getOperand
(
0
)
;
const
LAllocation
*
rhs
=
ins
-
>
getOperand
(
1
)
;
MMul
*
mul
=
ins
-
>
mir
(
)
;
if
(
rhs
-
>
isConstant
(
)
)
{
/
/
Bailout
on
-
0
.
0
int32
constant
=
ToInt32
(
rhs
)
;
if
(
mul
-
>
canBeNegativeZero
(
)
&
&
constant
<
=
0
)
{
Assembler
:
:
Condition
bailoutCond
=
(
constant
=
=
0
)
?
Assembler
:
:
LessThan
:
Assembler
:
:
Equal
;
masm
.
cmpl
(
ToOperand
(
lhs
)
Imm32
(
0
)
)
;
if
(
bailoutIf
(
bailoutCond
ins
-
>
snapshot
(
)
)
)
return
false
;
}
switch
(
constant
)
{
case
-
1
:
masm
.
negl
(
ToOperand
(
lhs
)
)
;
break
;
case
0
:
masm
.
xorl
(
ToOperand
(
lhs
)
ToRegister
(
lhs
)
)
;
return
true
;
/
/
escape
overflow
check
;
case
1
:
/
/
nop
return
true
;
/
/
escape
overflow
check
;
case
2
:
masm
.
addl
(
ToOperand
(
lhs
)
ToRegister
(
lhs
)
)
;
break
;
default
:
if
(
!
mul
-
>
canOverflow
(
)
&
&
constant
>
0
)
{
/
/
Use
shift
if
cannot
overflow
and
constant
is
power
of
2
int32
shift
=
JS_FloorLog2
(
constant
)
;
if
(
(
1
<
<
shift
)
=
=
constant
)
{
masm
.
shll
(
Imm32
(
shift
)
ToRegister
(
lhs
)
)
;
return
true
;
}
}
masm
.
imull
(
Imm32
(
ToInt32
(
rhs
)
)
ToRegister
(
lhs
)
)
;
}
/
/
Bailout
on
overflow
if
(
mul
-
>
canOverflow
(
)
&
&
!
bailoutIf
(
Assembler
:
:
Overflow
ins
-
>
snapshot
(
)
)
)
return
false
;
}
else
{
masm
.
imull
(
ToOperand
(
rhs
)
ToRegister
(
lhs
)
)
;
/
/
Bailout
on
overflow
if
(
mul
-
>
canOverflow
(
)
&
&
!
bailoutIf
(
Assembler
:
:
Overflow
ins
-
>
snapshot
(
)
)
)
return
false
;
/
/
Bailout
on
0
(
could
be
-
0
.
0
)
if
(
mul
-
>
canBeNegativeZero
(
)
)
{
masm
.
cmpl
(
ToOperand
(
lhs
)
Imm32
(
0
)
)
;
if
(
!
bailoutIf
(
Assembler
:
:
Equal
ins
-
>
snapshot
(
)
)
)
return
false
;
}
}
return
true
;
}
bool
CodeGeneratorX86Shared
:
:
visitBitNot
(
LBitNot
*
ins
)
{
const
LAllocation
*
input
=
ins
-
>
getOperand
(
0
)
;
JS_ASSERT
(
!
input
-
>
isConstant
(
)
)
;
masm
.
notl
(
ToOperand
(
input
)
)
;
return
true
;
}
bool
CodeGeneratorX86Shared
:
:
visitBitOp
(
LBitOp
*
ins
)
{
const
LAllocation
*
lhs
=
ins
-
>
getOperand
(
0
)
;
const
LAllocation
*
rhs
=
ins
-
>
getOperand
(
1
)
;
switch
(
ins
-
>
bitop
(
)
)
{
case
JSOP_BITOR
:
if
(
rhs
-
>
isConstant
(
)
)
masm
.
orl
(
Imm32
(
ToInt32
(
rhs
)
)
ToOperand
(
lhs
)
)
;
else
masm
.
orl
(
ToOperand
(
rhs
)
ToRegister
(
lhs
)
)
;
break
;
case
JSOP_BITXOR
:
if
(
rhs
-
>
isConstant
(
)
)
masm
.
xorl
(
Imm32
(
ToInt32
(
rhs
)
)
ToOperand
(
lhs
)
)
;
else
masm
.
xorl
(
ToOperand
(
rhs
)
ToRegister
(
lhs
)
)
;
break
;
case
JSOP_BITAND
:
if
(
rhs
-
>
isConstant
(
)
)
masm
.
andl
(
Imm32
(
ToInt32
(
rhs
)
)
ToOperand
(
lhs
)
)
;
else
masm
.
andl
(
ToOperand
(
rhs
)
ToRegister
(
lhs
)
)
;
break
;
default
:
JS_NOT_REACHED
(
"
unexpected
binary
opcode
"
)
;
}
return
true
;
}
bool
CodeGeneratorX86Shared
:
:
visitShiftOp
(
LShiftOp
*
ins
)
{
const
LAllocation
*
lhs
=
ins
-
>
getOperand
(
0
)
;
const
LAllocation
*
rhs
=
ins
-
>
getOperand
(
1
)
;
switch
(
ins
-
>
bitop
(
)
)
{
case
JSOP_LSH
:
if
(
rhs
-
>
isConstant
(
)
)
masm
.
shll
(
Imm32
(
ToInt32
(
rhs
)
&
0x1F
)
ToRegister
(
lhs
)
)
;
else
masm
.
shll_cl
(
ToRegister
(
lhs
)
)
;
break
;
case
JSOP_RSH
:
if
(
rhs
-
>
isConstant
(
)
)
masm
.
sarl
(
Imm32
(
ToInt32
(
rhs
)
&
0x1F
)
ToRegister
(
lhs
)
)
;
else
masm
.
sarl_cl
(
ToRegister
(
lhs
)
)
;
break
;
case
JSOP_URSH
:
{
MUrsh
*
ursh
=
ins
-
>
mir
(
)
-
>
toUrsh
(
)
;
if
(
rhs
-
>
isConstant
(
)
)
masm
.
shrl
(
Imm32
(
ToInt32
(
rhs
)
&
0x1F
)
ToRegister
(
lhs
)
)
;
else
masm
.
shrl_cl
(
ToRegister
(
lhs
)
)
;
/
/
Note
:
this
is
an
unsigned
operation
.
/
/
We
don
'
t
have
a
UINT32
type
so
we
will
emulate
this
with
INT32
/
/
The
bit
representation
of
an
integer
from
ToInt32
and
ToUint32
are
the
same
.
/
/
So
the
inputs
are
ok
.
/
/
But
we
need
to
bring
the
output
back
again
from
UINT32
to
INT32
.
/
/
Both
representation
overlap
each
other
in
the
positive
numbers
.
(
in
INT32
)
/
/
So
there
is
only
a
problem
when
solution
(
in
INT32
)
is
negative
.
if
(
ursh
-
>
canOverflow
(
)
)
{
masm
.
cmpl
(
ToOperand
(
lhs
)
Imm32
(
0
)
)
;
if
(
!
bailoutIf
(
Assembler
:
:
LessThan
ins
-
>
snapshot
(
)
)
)
return
false
;
}
break
;
}
default
:
JS_NOT_REACHED
(
"
unexpected
shift
opcode
"
)
;
}
return
true
;
}
bool
CodeGeneratorX86Shared
:
:
visitInteger
(
LInteger
*
ins
)
{
const
LDefinition
*
def
=
ins
-
>
getDef
(
0
)
;
masm
.
movl
(
Imm32
(
ins
-
>
getValue
(
)
)
ToRegister
(
def
)
)
;
return
true
;
}
typedef
MoveResolver
:
:
MoveOperand
MoveOperand
;
MoveOperand
CodeGeneratorX86Shared
:
:
toMoveOperand
(
const
LAllocation
*
a
)
const
{
if
(
a
-
>
isGeneralReg
(
)
)
return
MoveOperand
(
ToRegister
(
a
)
)
;
if
(
a
-
>
isFloatReg
(
)
)
return
MoveOperand
(
ToFloatRegister
(
a
)
)
;
return
MoveOperand
(
StackPointer
ToStackOffset
(
a
)
)
;
}
bool
CodeGeneratorX86Shared
:
:
visitMoveGroup
(
LMoveGroup
*
group
)
{
if
(
!
group
-
>
numMoves
(
)
)
return
true
;
MoveResolver
&
resolver
=
masm
.
moveResolver
(
)
;
for
(
size_t
i
=
0
;
i
<
group
-
>
numMoves
(
)
;
i
+
+
)
{
const
LMove
&
move
=
group
-
>
getMove
(
i
)
;
const
LAllocation
*
from
=
move
.
from
(
)
;
const
LAllocation
*
to
=
move
.
to
(
)
;
/
/
No
bogus
moves
.
JS_ASSERT
(
*
from
!
=
*
to
)
;
JS_ASSERT
(
!
from
-
>
isConstant
(
)
)
;
JS_ASSERT
(
from
-
>
isDouble
(
)
=
=
to
-
>
isDouble
(
)
)
;
MoveResolver
:
:
Move
:
:
Kind
kind
=
from
-
>
isDouble
(
)
?
MoveResolver
:
:
Move
:
:
DOUBLE
:
MoveResolver
:
:
Move
:
:
GENERAL
;
if
(
!
resolver
.
addMove
(
toMoveOperand
(
from
)
toMoveOperand
(
to
)
kind
)
)
return
false
;
}
if
(
!
resolver
.
resolve
(
)
)
return
false
;
MoveEmitter
emitter
(
masm
)
;
emitter
.
emit
(
resolver
)
;
emitter
.
finish
(
)
;
return
true
;
}
bool
CodeGeneratorX86Shared
:
:
visitTableSwitch
(
LTableSwitch
*
ins
)
{
MTableSwitch
*
mir
=
ins
-
>
mir
(
)
;
const
LAllocation
*
input
=
ins
-
>
getOperand
(
0
)
;
/
/
Put
input
in
temp
.
register
LDefinition
*
index
=
ins
-
>
getTemp
(
0
)
;
masm
.
mov
(
ToOperand
(
input
)
ToRegister
(
index
)
)
;
/
/
Lower
value
with
low
value
if
(
mir
-
>
low
(
)
!
=
0
)
masm
.
subl
(
Imm32
(
mir
-
>
low
(
)
)
ToOperand
(
index
)
)
;
/
/
Jump
to
default
case
if
input
is
out
of
range
LBlock
*
defaultcase
=
mir
-
>
getDefault
(
)
-
>
lir
(
)
;
int32
cases
=
mir
-
>
numCases
(
)
;
masm
.
cmpl
(
ToOperand
(
index
)
Imm32
(
cases
)
)
;
masm
.
j
(
AssemblerX86Shared
:
:
AboveOrEqual
defaultcase
-
>
label
(
)
)
;
/
/
Create
a
label
pointing
to
the
jumptable
/
/
This
gets
patched
after
linking
CodeLabel
*
label
=
new
CodeLabel
(
)
;
if
(
!
masm
.
addCodeLabel
(
label
)
)
return
false
;
/
/
Compute
the
pointer
to
the
right
case
in
the
second
temp
.
register
LDefinition
*
base
=
ins
-
>
getTemp
(
1
)
;
masm
.
mov
(
label
-
>
dest
(
)
ToRegister
(
base
)
)
;
Operand
pointer
=
Operand
(
ToRegister
(
base
)
ToRegister
(
index
)
TimesEight
)
;
masm
.
lea
(
pointer
ToRegister
(
base
)
)
;
/
/
Jump
to
the
right
case
masm
.
jmp
(
ToOperand
(
base
)
)
;
/
/
Create
the
jumptable
/
/
Every
jump
statements
get
aligned
on
pointersize
/
/
That
way
there
is
always
2
*
pointersize
between
each
jump
statement
.
masm
.
align
(
1
<
<
TimesFour
)
;
masm
.
bind
(
label
-
>
src
(
)
)
;
for
(
uint
j
=
0
;
j
<
ins
-
>
mir
(
)
-
>
numCases
(
)
;
j
+
+
)
{
LBlock
*
caseblock
=
ins
-
>
mir
(
)
-
>
getCase
(
j
)
-
>
lir
(
)
;
masm
.
jmp
(
caseblock
-
>
label
(
)
)
;
masm
.
align
(
1
<
<
TimesFour
)
;
}
return
true
;
}
bool
CodeGeneratorX86Shared
:
:
visitMathD
(
LMathD
*
math
)
{
const
LAllocation
*
input
=
math
-
>
getOperand
(
1
)
;
const
LDefinition
*
output
=
math
-
>
getDef
(
0
)
;
switch
(
math
-
>
jsop
(
)
)
{
case
JSOP_ADD
:
masm
.
addsd
(
ToFloatRegister
(
input
)
ToFloatRegister
(
output
)
)
;
break
;
case
JSOP_MUL
:
masm
.
mulsd
(
ToFloatRegister
(
input
)
ToFloatRegister
(
output
)
)
;
default
:
JS_NOT_REACHED
(
"
unexpected
opcode
"
)
;
return
false
;
}
return
true
;
}
/
/
Checks
whether
a
double
is
representable
as
a
32
-
bit
integer
.
If
so
the
/
/
integer
is
written
to
the
output
register
.
Otherwise
a
bailout
is
taken
to
/
/
the
given
snapshot
.
This
function
overwrites
the
scratch
float
register
.
bool
CodeGeneratorX86Shared
:
:
emitDoubleToInt32
(
const
FloatRegister
&
src
const
Register
&
dest
LSnapshot
*
snapshot
)
{
/
/
Note
that
we
don
'
t
specify
the
destination
width
for
the
truncated
/
/
conversion
to
integer
.
x64
will
use
the
native
width
(
quadword
)
which
/
/
sign
-
extends
the
top
bits
preserving
a
little
sanity
.
masm
.
cvttsd2s
(
src
dest
)
;
masm
.
cvtsi2sd
(
dest
ScratchFloatReg
)
;
masm
.
ucomisd
(
src
ScratchFloatReg
)
;
if
(
!
bailoutIf
(
Assembler
:
:
Parity
snapshot
)
)
return
false
;
if
(
!
bailoutIf
(
Assembler
:
:
NotEqual
snapshot
)
)
return
false
;
/
/
Check
for
-
0
Label
notZero
;
masm
.
testl
(
dest
dest
)
;
masm
.
j
(
Assembler
:
:
NonZero
&
notZero
)
;
if
(
Assembler
:
:
HasSSE41
(
)
)
{
masm
.
ptest
(
src
src
)
;
if
(
!
bailoutIf
(
Assembler
:
:
NonZero
snapshot
)
)
return
false
;
}
else
{
/
/
bit
0
=
sign
of
low
double
/
/
bit
1
=
sign
of
high
double
masm
.
movmskpd
(
src
dest
)
;
masm
.
andl
(
Imm32
(
1
)
dest
)
;
if
(
!
bailoutIf
(
Assembler
:
:
NonZero
snapshot
)
)
return
false
;
}
masm
.
bind
(
&
notZero
)
;
return
true
;
}
