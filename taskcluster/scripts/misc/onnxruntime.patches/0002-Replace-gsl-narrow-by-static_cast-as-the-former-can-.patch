From
0f02f0a222923dde8f7d81a8f2667dc6c15e8330
Mon
Sep
17
00
:
00
:
00
2001
From
:
serge
-
sans
-
paille
<
sguelton
mozilla
.
com
>
Date
:
Tue
13
May
2025
12
:
13
:
22
+
0200
Subject
:
[
PATCH
2
/
5
]
Replace
gsl
:
:
narrow
by
static_cast
as
the
former
can
throw
exception
-
-
-
.
.
.
/
core
/
framework
/
kernel_type_str_resolver
.
cc
|
2
+
-
.
.
.
/
graph
/
runtime_optimization_record_container
.
cc
|
2
+
-
onnxruntime
/
core
/
optimizer
/
attention_fusion
.
cc
|
8
+
+
+
+
-
-
-
-
.
.
.
/
core
/
optimizer
/
embed_layer_norm_fusion
.
cc
|
6
+
+
+
-
-
-
onnxruntime
/
core
/
optimizer
/
nchwc_transformer
.
cc
|
12
+
+
+
+
+
+
-
-
-
-
-
-
onnxruntime
/
core
/
optimizer
/
utils
.
cc
|
4
+
+
-
-
6
files
changed
17
insertions
(
+
)
17
deletions
(
-
)
diff
-
-
git
a
/
onnxruntime
/
core
/
framework
/
kernel_type_str_resolver
.
cc
b
/
onnxruntime
/
core
/
framework
/
kernel_type_str_resolver
.
cc
index
3142f94f28
.
.
b64ed160da
100644
-
-
-
a
/
onnxruntime
/
core
/
framework
/
kernel_type_str_resolver
.
cc
+
+
+
b
/
onnxruntime
/
core
/
framework
/
kernel_type_str_resolver
.
cc
-
167
7
+
167
7
Status
KernelTypeStrResolver
:
:
SaveToOrtFormat
(
auto
fbs_arg
=
fbs
:
:
CreateArgTypeAndIndex
(
builder
arg
.
first
=
=
ArgType
:
:
kInput
?
fbs
:
:
ArgType
:
:
INPUT
:
fbs
:
:
ArgType
:
:
OUTPUT
-
gsl
:
:
narrow
<
uint32_t
>
(
arg
.
second
)
)
;
+
static_cast
<
uint32_t
>
(
arg
.
second
)
)
;
fbs_args
.
push_back
(
fbs_arg
)
;
}
diff
-
-
git
a
/
onnxruntime
/
core
/
graph
/
runtime_optimization_record_container
.
cc
b
/
onnxruntime
/
core
/
graph
/
runtime_optimization_record_container
.
cc
index
2d0e1076ee
.
.
36a0f37a27
100644
-
-
-
a
/
onnxruntime
/
core
/
graph
/
runtime_optimization_record_container
.
cc
+
+
+
b
/
onnxruntime
/
core
/
graph
/
runtime_optimization_record_container
.
cc
-
57
7
+
57
7
static
Status
SaveRuntimeOptimizationRecordToOrtFormat
(
const
auto
fbs_node_indices
=
builder
.
CreateVector
<
uint32_t
>
(
nodes_to_optimize_indices
.
nodes
.
size
(
)
-
[
&
]
(
size_t
i
)
{
return
gsl
:
:
narrow
<
uint32_t
>
(
nodes_to_optimize_indices
.
nodes
[
i
]
)
;
}
)
;
+
[
&
]
(
size_t
i
)
{
return
static_cast
<
uint32_t
>
(
nodes_to_optimize_indices
.
nodes
[
i
]
)
;
}
)
;
const
auto
fbs_nodes_to_optimize
=
fbs
:
:
CreateNodesToOptimizeIndices
(
builder
diff
-
-
git
a
/
onnxruntime
/
core
/
optimizer
/
attention_fusion
.
cc
b
/
onnxruntime
/
core
/
optimizer
/
attention_fusion
.
cc
index
ff8943de79
.
.
6186fb542f
100644
-
-
-
a
/
onnxruntime
/
core
/
optimizer
/
attention_fusion
.
cc
+
+
+
b
/
onnxruntime
/
core
/
optimizer
/
attention_fusion
.
cc
-
121
25
+
121
25
static
NodeArg
&
MergeQkvWeights
(
Graph
&
graph
int64_t
hidden_size
const
float
*
k_weight
=
k_initializer
.
data
<
float
>
(
)
;
const
float
*
v_weight
=
v_initializer
.
data
<
float
>
(
)
;
std
:
:
vector
<
float
>
result
;
-
result
.
reserve
(
gsl
:
:
narrow
<
size_t
>
(
element_count
)
)
;
+
result
.
reserve
(
static_cast
<
size_t
>
(
element_count
)
)
;
if
(
is_matmul
)
{
MergeMatMulWeights
<
float
>
(
q_weight
k_weight
v_weight
result
hidden_size
)
;
}
else
{
MergeWeights
<
float
>
(
q_weight
k_weight
v_weight
result
hidden_size
)
;
}
-
utils
:
:
SetRawDataInTensorProto
(
initializer
result
.
data
(
)
gsl
:
:
narrow
<
size_t
>
(
element_count
)
*
sizeof
(
float
)
)
;
+
utils
:
:
SetRawDataInTensorProto
(
initializer
result
.
data
(
)
static_cast
<
size_t
>
(
element_count
)
*
sizeof
(
float
)
)
;
}
else
{
/
/
data_type
=
=
ONNX_NAMESPACE
:
:
TensorProto_DataType_FLOAT16
const
MLFloat16
*
q_weight
=
q_initializer
.
data
<
MLFloat16
>
(
)
;
const
MLFloat16
*
k_weight
=
k_initializer
.
data
<
MLFloat16
>
(
)
;
const
MLFloat16
*
v_weight
=
v_initializer
.
data
<
MLFloat16
>
(
)
;
std
:
:
vector
<
MLFloat16
>
result
;
-
result
.
reserve
(
gsl
:
:
narrow
<
size_t
>
(
element_count
)
)
;
+
result
.
reserve
(
static_cast
<
size_t
>
(
element_count
)
)
;
if
(
is_matmul
)
{
MergeMatMulWeights
<
MLFloat16
>
(
q_weight
k_weight
v_weight
result
hidden_size
)
;
}
else
{
MergeWeights
<
MLFloat16
>
(
q_weight
k_weight
v_weight
result
hidden_size
)
;
}
-
utils
:
:
SetRawDataInTensorProto
(
initializer
result
.
data
(
)
gsl
:
:
narrow
<
size_t
>
(
element_count
)
*
sizeof
(
MLFloat16
)
)
;
+
utils
:
:
SetRawDataInTensorProto
(
initializer
result
.
data
(
)
static_cast
<
size_t
>
(
element_count
)
*
sizeof
(
MLFloat16
)
)
;
}
return
graph_utils
:
:
AddInitializer
(
graph
initializer
)
;
diff
-
-
git
a
/
onnxruntime
/
core
/
optimizer
/
embed_layer_norm_fusion
.
cc
b
/
onnxruntime
/
core
/
optimizer
/
embed_layer_norm_fusion
.
cc
index
103e72072f
.
.
d91529273e
100644
-
-
-
a
/
onnxruntime
/
core
/
optimizer
/
embed_layer_norm_fusion
.
cc
+
+
+
b
/
onnxruntime
/
core
/
optimizer
/
embed_layer_norm_fusion
.
cc
-
431
7
+
431
7
template
<
typename
T
>
bool
CheckEmbeddingData
(
const
T
*
data
int64_t
batch_size
int64_t
element_count
)
{
/
/
check
that
all
batches
has
same
data
.
size_t
data_length
=
SafeInt
<
size_t
>
(
batch_size
)
*
element_count
;
-
for
(
size_t
i
=
gsl
:
:
narrow
<
size_t
>
(
element_count
)
;
i
<
data_length
;
i
+
+
)
{
+
for
(
size_t
i
=
static_cast
<
size_t
>
(
element_count
)
;
i
<
data_length
;
i
+
+
)
{
if
(
data
[
i
]
!
=
data
[
i
%
element_count
]
)
{
return
false
;
}
-
465
13
+
465
13
static
NodeArg
*
ExtractEmbedding
(
Graph
&
graph
if
(
!
CheckEmbeddingData
(
data
batch_size
element_count
)
)
{
return
nullptr
;
}
-
utils
:
:
SetRawDataInTensorProto
(
initializer
data
gsl
:
:
narrow
<
size_t
>
(
element_count
)
*
sizeof
(
float
)
)
;
+
utils
:
:
SetRawDataInTensorProto
(
initializer
data
static_cast
<
size_t
>
(
element_count
)
*
sizeof
(
float
)
)
;
}
else
{
/
/
data_type
=
=
ONNX_NAMESPACE
:
:
TensorProto_DataType_FLOAT16
const
MLFloat16
*
data
=
old_initializer
.
data
<
MLFloat16
>
(
)
;
if
(
!
CheckEmbeddingData
(
data
batch_size
element_count
)
)
{
return
nullptr
;
}
-
utils
:
:
SetRawDataInTensorProto
(
initializer
data
gsl
:
:
narrow
<
size_t
>
(
element_count
)
*
sizeof
(
MLFloat16
)
)
;
+
utils
:
:
SetRawDataInTensorProto
(
initializer
data
static_cast
<
size_t
>
(
element_count
)
*
sizeof
(
MLFloat16
)
)
;
}
NodeArg
&
node_arg
=
graph_utils
:
:
AddInitializer
(
graph
initializer
)
;
diff
-
-
git
a
/
onnxruntime
/
core
/
optimizer
/
nchwc_transformer
.
cc
b
/
onnxruntime
/
core
/
optimizer
/
nchwc_transformer
.
cc
index
46f306b92b
.
.
436f16661f
100644
-
-
-
a
/
onnxruntime
/
core
/
optimizer
/
nchwc_transformer
.
cc
+
+
+
b
/
onnxruntime
/
core
/
optimizer
/
nchwc_transformer
.
cc
-
415
7
+
415
7
void
NchwcTransformerImpl
:
:
TransformConv
(
Node
&
node
)
{
for
(
size_t
i
=
2
;
i
<
4
;
i
+
+
)
{
reordered_filter_size
*
=
conv_W_dims
[
i
]
;
}
-
InlinedVector
<
float
>
reordered_filter
(
gsl
:
:
narrow
<
size_t
>
(
reordered_filter_size
)
)
;
+
InlinedVector
<
float
>
reordered_filter
(
static_cast
<
size_t
>
(
reordered_filter_size
)
)
;
/
/
Reorder
the
weights
tensor
statically
.
if
(
reorder_filter_OIHWBo
)
{
-
451
7
+
451
7
void
NchwcTransformerImpl
:
:
TransformConv
(
Node
&
node
)
{
}
else
{
Initializer
conv_B
{
*
conv_B_tensor_proto
graph_
.
ModelPath
(
)
}
;
-
InlinedVector
<
float
>
aligned_bias
(
gsl
:
:
narrow
<
size_t
>
(
nchwc_output_channels
)
)
;
+
InlinedVector
<
float
>
aligned_bias
(
static_cast
<
size_t
>
(
nchwc_output_channels
)
)
;
ORT_ENFORCE
(
output_channels
<
=
nchwc_output_channels
"
Buffer
overflow
"
)
;
std
:
:
copy_n
(
conv_B
.
data
<
float
>
(
)
output_channels
aligned_bias
.
data
(
)
)
;
-
460
7
+
460
7
void
NchwcTransformerImpl
:
:
TransformConv
(
Node
&
node
)
{
nchwc_conv_B_tensor_proto
.
set_data_type
(
ONNX_NAMESPACE
:
:
TensorProto_DataType_FLOAT
)
;
nchwc_conv_B_tensor_proto
.
set_name
(
graph_
.
GenerateNodeArgName
(
"
reorder
"
)
)
;
utils
:
:
SetRawDataInTensorProto
(
nchwc_conv_B_tensor_proto
aligned_bias
.
data
(
)
-
gsl
:
:
narrow
<
size_t
>
(
nchwc_output_channels
)
*
sizeof
(
float
)
)
;
+
static_cast
<
size_t
>
(
nchwc_output_channels
)
*
sizeof
(
float
)
)
;
nchwc_conv_B_tensor_proto
.
add_dims
(
nchwc_output_channels
)
;
-
878
7
+
878
7
void
NchwcTransformerImpl
:
:
TransformBatchNormalization
(
Node
&
node
)
{
const
size_t
nchwc_block_size
=
MlasNchwcGetBlockSize
(
)
;
const
int64_t
nchwc_channels
=
(
channels
+
nchwc_block_size
-
1
)
&
~
(
nchwc_block_size
-
1
)
;
-
InlinedVector
<
float
>
padded_buffer
(
gsl
:
:
narrow
<
size_t
>
(
nchwc_channels
)
)
;
+
InlinedVector
<
float
>
padded_buffer
(
static_cast
<
size_t
>
(
nchwc_channels
)
)
;
std
:
:
copy_n
(
bn_scale
.
data
<
float
>
(
)
channels
padded_buffer
.
data
(
)
)
;
-
886
7
+
886
7
void
NchwcTransformerImpl
:
:
TransformBatchNormalization
(
Node
&
node
)
{
nchwc_conv_W_tensor_proto
.
set_data_type
(
ONNX_NAMESPACE
:
:
TensorProto_DataType_FLOAT
)
;
nchwc_conv_W_tensor_proto
.
set_name
(
graph_
.
GenerateNodeArgName
(
"
bn_scale
"
)
)
;
utils
:
:
SetRawDataInTensorProto
(
nchwc_conv_W_tensor_proto
padded_buffer
.
data
(
)
-
gsl
:
:
narrow
<
size_t
>
(
nchwc_channels
)
*
sizeof
(
float
)
)
;
+
static_cast
<
size_t
>
(
nchwc_channels
)
*
sizeof
(
float
)
)
;
nchwc_conv_W_tensor_proto
.
add_dims
(
nchwc_channels
)
;
nchwc_conv_W_tensor_proto
.
add_dims
(
1
)
;
nchwc_conv_W_tensor_proto
.
add_dims
(
1
)
;
-
900
7
+
900
7
void
NchwcTransformerImpl
:
:
TransformBatchNormalization
(
Node
&
node
)
{
nchwc_conv_B_tensor_proto
.
set_data_type
(
ONNX_NAMESPACE
:
:
TensorProto_DataType_FLOAT
)
;
nchwc_conv_B_tensor_proto
.
set_name
(
graph_
.
GenerateNodeArgName
(
"
bn_B
"
)
)
;
utils
:
:
SetRawDataInTensorProto
(
nchwc_conv_B_tensor_proto
padded_buffer
.
data
(
)
-
gsl
:
:
narrow
<
size_t
>
(
nchwc_channels
)
*
sizeof
(
float
)
)
;
+
static_cast
<
size_t
>
(
nchwc_channels
)
*
sizeof
(
float
)
)
;
nchwc_conv_B_tensor_proto
.
add_dims
(
nchwc_channels
)
;
auto
*
nchwc_conv_B_arg
=
&
graph_utils
:
:
AddInitializer
(
graph_
nchwc_conv_B_tensor_proto
)
;
diff
-
-
git
a
/
onnxruntime
/
core
/
optimizer
/
utils
.
cc
b
/
onnxruntime
/
core
/
optimizer
/
utils
.
cc
index
c7e11de348
.
.
047d095aaf
100644
-
-
-
a
/
onnxruntime
/
core
/
optimizer
/
utils
.
cc
+
+
+
b
/
onnxruntime
/
core
/
optimizer
/
utils
.
cc
-
175
11
+
175
11
bool
AppendTensorFromInitializer
(
const
Graph
&
graph
const
NodeArg
&
input_arg
I
const
auto
data_type
=
tensor_proto
-
>
data_type
(
)
;
if
(
data_type
=
=
ONNX_NAMESPACE
:
:
TensorProto_DataType_INT64
)
{
const
int64_t
*
val
=
init_const
.
data
<
int64_t
>
(
)
;
-
data
.
reserve
(
data
.
size
(
)
+
gsl
:
:
narrow
<
size_t
>
(
init_const
.
size
(
)
)
)
;
+
data
.
reserve
(
data
.
size
(
)
+
static_cast
<
size_t
>
(
init_const
.
size
(
)
)
)
;
data
.
insert
(
data
.
end
(
)
val
val
+
init_const
.
size
(
)
)
;
}
else
if
(
data_type
=
=
ONNX_NAMESPACE
:
:
TensorProto_DataType_INT32
)
{
const
int32_t
*
val
=
init_const
.
data
<
int32_t
>
(
)
;
-
data
.
reserve
(
data
.
size
(
)
+
gsl
:
:
narrow
<
size_t
>
(
init_const
.
size
(
)
)
)
;
+
data
.
reserve
(
data
.
size
(
)
+
static_cast
<
size_t
>
(
init_const
.
size
(
)
)
)
;
for
(
size_t
i
=
0
;
i
<
init_const
.
size
(
)
;
i
+
+
)
{
data
.
push_back
(
static_cast
<
int64_t
>
(
val
[
i
]
)
)
;
}
-
-
2
.
49
.
0
